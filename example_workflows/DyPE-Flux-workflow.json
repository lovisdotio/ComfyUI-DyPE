{
  "id": "908d0bfb-e192-4627-9b57-147496e6e2dd",
  "revision": 0,
  "last_node_id": 70,
  "last_link_id": 119,
  "nodes": [
    {
      "id": 40,
      "type": "DualCLIPLoader",
      "pos": [
        -320,
        290
      ],
      "size": [
        270,
        130
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            64
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "DualCLIPLoader",
        "models": [
          {
            "name": "clip_l.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
            "directory": "text_encoders"
          },
          {
            "name": "t5xxl_fp16.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp16.safetensors",
        "flux",
        "default"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 43,
      "type": "MarkdownNote",
      "pos": [
        -870,
        110
      ],
      "size": [
        520,
        390
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {},
      "widgets_values": [
        "## Model links\n\n**Diffusion Model**\n\n- [flux1-krea-dev_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/FLUX.1-Krea-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-krea-dev_fp8_scaled.safetensors)\n\nIf you need the original weights, head to [black-forest-labs/FLUX.1-Krea-dev](https://huggingface.co/black-forest-labs/FLUX.1-Krea-dev/), accept the agreement in the repo, then click the link below to download the models:\n\n- [flux1-krea-dev.safetensors](https://huggingface.co/black-forest-labs/FLUX.1-Krea-dev/resolve/main/flux1-krea-dev.safetensors)\n\n**Text Encoder**\n\n- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)\n\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\n**VAE**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors)\n\n\n```\nComfyUI/\n├── models/\n│   ├── diffusion_models/\n│   │   └─── flux1-krea-dev_fp8_scaled.safetensors\n│   ├── text_encoders/\n│   │   ├── clip_l.safetensors\n│   │   └─── t5xxl_fp16.safetensors # or t5xxl_fp8_e4m3fn_scaled.safetensors\n│   └── vae/\n│       └── ae.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -320,
        470
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            77,
            85
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "FLUX1\\ae.safetensors"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        391.97558139331176,
        122.95473372107558
      ],
      "size": [
        319.2356335124862,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 52
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 85
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": []
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "VAEDecode"
      },
      "widgets_values": []
    },
    {
      "id": 55,
      "type": "VAEDecodeTiled",
      "pos": [
        391.97558139331176,
        226.612614517858
      ],
      "size": [
        322.89304359551966,
        150
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 112
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 77
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            91
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.66",
        "Node name for S&R": "VAEDecodeTiled"
      },
      "widgets_values": [
        256,
        64,
        64,
        8
      ]
    },
    {
      "id": 53,
      "type": "ModelPatchTorchSettings",
      "pos": [
        30.020388325880088,
        958.5302639048878
      ],
      "size": [
        280,
        58
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 71
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            73
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "5dcda71011870278c35d92ff77a677ed2e538f2d",
        "Node name for S&R": "ModelPatchTorchSettings",
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        true
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 38,
      "type": "UNETLoader",
      "pos": [
        -320,
        150
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            118
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "UNETLoader",
        "models": [
          {
            "name": "flux1-krea-dev_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/FLUX.1-Krea-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-krea-dev_fp8_scaled.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": [
        "FLUX1\\flux1-krea-dev.safetensors",
        "default"
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 27,
      "type": "EmptySD3LatentImage",
      "pos": [
        -320,
        630
      ],
      "size": [
        270,
        120
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            51
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        2048,
        3072,
        1
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        757.2214793721178,
        123.42500709283193
      ],
      "size": [
        640,
        660
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 91
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "SaveImage"
      },
      "widgets_values": [
        "flux_krea/flux_krea"
      ]
    },
    {
      "id": 45,
      "type": "CLIPTextEncode",
      "pos": [
        7.045080197257759,
        159.16529405661166
      ],
      "size": [
        330,
        210
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 64
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            66,
            111
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.47",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "A muscular, bald man holds a flower above his head with both arms, set against a soft circular background in black and white."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 42,
      "type": "ConditioningZeroOut",
      "pos": [
        151.75751860615074,
        416.7514387263594
      ],
      "size": [
        200,
        30
      ],
      "flags": {
        "collapsed": true
      },
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 66
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "ConditioningZeroOut"
      },
      "widgets_values": []
    },
    {
      "id": 52,
      "type": "PathchSageAttentionKJ",
      "pos": [
        30.97067656870301,
        849.9776697194811
      ],
      "size": [
        280,
        58
      ],
      "flags": {
        "collapsed": false
      },
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 119
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            71
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfyui-kjnodes",
        "ver": "5dcda71011870278c35d92ff77a677ed2e538f2d",
        "Node name for S&R": "PathchSageAttentionKJ",
        "ue_properties": {
          "version": "7.0.1",
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": [
        "auto"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 68,
      "type": "DyPE_FLUX",
      "pos": [
        34.378266361112125,
        592.0845558725733
      ],
      "size": [
        273.70012497212906,
        202
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 118
        }
      ],
      "outputs": [
        {
          "name": "Patched Model",
          "type": "MODEL",
          "links": [
            119
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "DyPE_FLUX"
      },
      "widgets_values": [
        1024,
        1024,
        "yarn",
        true,
        3,
        0.1,
        0.8
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 70,
      "type": "Note",
      "pos": [
        370.8346374838202,
        962.8353927340362
      ],
      "size": [
        210,
        88
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "DyPE width/height - Keep the values below 1024x1024; doing so won’t affect your output.\n"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 69,
      "type": "MarkdownNote",
      "pos": [
        -866.3440753786277,
        557.8510364476188
      ],
      "size": [
        519.2421649643175,
        338.01057378012047
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "DyPE",
      "properties": {
        "ue_properties": {
          "widget_ue_connectable": {},
          "version": "7.1",
          "input_ue_unconnectable": {}
        }
      },
      "widgets_values": [
        "### Node Inputs\n\n*   **`model`**: The FLUX model to be patched.\n*   **`width` / `height`**: The target image resolution. **This must match the resolution set in your `Empty Latent Image` node.**\n*   **`method`**: The core position encoding extrapolation method. `yarn` is the recommended default, as it forms the basis of the paper's best-performing \"DY-YaRN\" variant.\n*   **`enable_dype`**: Enables or disables the **dynamic, time-aware** component of DyPE.\n*   **`dype_exponent`**: Controls the \"strength\" of the dynamic effect over time. This is the most important tuning parameter.\n    *   `2.0` (Exponential): Recommended for **4K+** resolutions. It's an aggressive schedule that transitions quickly.\n    *   `1.0` (Linear): A good starting point for **~2K-3K** resolutions.\n    *   `0.5` (Sub-linear): A gentler schedule that may work best for resolutions just above the model's native 1K.\n*   **`base_shift` / `max_shift`** (Advanced): Adjust only if you are an advanced user experimenting with the noise schedule.\n\n\n\n## Join\n\n### [TokenDiffusion](https://t.me/TokenDiff) - AI for every home, creativity for every mind!\n\n### [TokenDiff Community Hub](https://t.me/TokenDiff_hub) - Questions, help, and thoughtful discussion. "
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 31,
      "type": "KSampler",
      "pos": [
        395.5510343546297,
        433.7293334706151
      ],
      "size": [
        315,
        474.00000000000006
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 73
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 111
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 110
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 51
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            52,
            112
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        42,
        "fixed",
        30,
        1,
        "euler",
        "beta",
        1
      ]
    }
  ],
  "links": [
    [
      51,
      27,
      0,
      31,
      3,
      "LATENT"
    ],
    [
      52,
      31,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      64,
      40,
      0,
      45,
      0,
      "CLIP"
    ],
    [
      66,
      45,
      0,
      42,
      0,
      "CONDITIONING"
    ],
    [
      71,
      52,
      0,
      53,
      0,
      "MODEL"
    ],
    [
      73,
      53,
      0,
      31,
      0,
      "MODEL"
    ],
    [
      77,
      39,
      0,
      55,
      1,
      "VAE"
    ],
    [
      85,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      91,
      55,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      110,
      42,
      0,
      31,
      2,
      "CONDITIONING"
    ],
    [
      111,
      45,
      0,
      31,
      1,
      "CONDITIONING"
    ],
    [
      112,
      31,
      0,
      55,
      0,
      "LATENT"
    ],
    [
      118,
      38,
      0,
      68,
      0,
      "MODEL"
    ],
    [
      119,
      68,
      0,
      52,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1 - Load Models Here",
      "bounding": [
        -330,
        80,
        300,
        460
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 2 - Image Size",
      "bounding": [
        -330,
        560,
        300,
        200
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step 3 - Prompt",
      "bounding": [
        -10,
        80,
        361.9005764856456,
        399.16989485829595
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 5,
      "title": "Model patch",
      "bounding": [
        -7.575982245696814,
        506.15777888556613,
        357.2928781597926,
        546.8190068170823
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7627768444385601,
      "offset": [
        1067.6762292181238,
        -14.895608507226342
      ]
    },
    "frontendVersion": "1.28.7",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}